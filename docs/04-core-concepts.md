# Core Concepts

The `clogs` system is built around a few core concepts that handle the discovery, parsing, and analysis of Claude AI transcripts. Understanding these concepts is essential for both using the CLI effectively and integrating with the Go library.

## 1. Claude Transcripts

The foundational data source for `clogs` is the collection of transcript files generated by the Claude AI environment.

-   **Location:** These transcripts are stored as JSON Lines (`.jsonl`) files in the `~/.claude/projects/` directory. Each session with Claude creates a new transcript file.
-   **Format:** Each line in a `.jsonl` file is a self-contained JSON object representing an event or message in the session.
-   **Structure:** The primary data structure, as defined in `internal/transcript/parser.go`, is the `TranscriptEntry`. It contains metadata about each event, including:
    -   `SessionID`: A unique identifier for the conversation session.
    -   `Message`: A nested object containing the actual message content, role, and usage statistics.
    -   `Timestamp`: The time the event occurred.
    -   `Type`: The type of event, such as `user` or `assistant`.
    -   `UUID` and `ParentUUID`: Identifiers for linking messages in the conversation tree.

## 2. Message Parsing

The `Parser` component is responsible for reading the raw `.jsonl` transcripts and converting them into a structured, simplified format.

-   **Functionality:** The `Parser` reads a given transcript file, processing each line as a distinct JSON object. It is designed to handle potentially very large lines by using a buffered scanner with an increased token size, preventing errors with long log entries.
-   **Extraction:** It identifies entries that represent actual user or assistant messages and extracts relevant information into a simplified `ExtractedMessage` struct. This struct normalizes the data and includes key fields such as:
    -   `SessionID`
    -   `MessageID`
    -   `Timestamp`
    -   `Role` (`user` or `assistant`)
    -   `Content` (the textual content of the message)
    -   `RawContent` (the original JSON content)
    -   `Metadata` (a map containing additional information like token usage and model name)

## 3. Real-time Monitoring

The `Monitor` provides the capability to process transcripts in near real-time as they are being written.

-   **Role:** As defined in `internal/transcript/monitor.go`, the `Monitor`'s purpose is to periodically scan active Claude sessions, detect new messages, parse them, and store them in a database.
-   **Offset Tracking:** To avoid reprocessing the entire transcript file on each check, the `Monitor` maintains a byte offset for each session file. It reads the file starting from the last known offset, processes any new lines, and then saves the new offset to the database. This makes the monitoring process efficient.
-   **Database Integration:** Once new messages are parsed, the `Monitor` stores the resulting `ExtractedMessage` objects in a database. This provides a persistent, queryable history of all conversations, which is used by other parts of the system and can be leveraged by external tools.

## 4. AI Summarization

The `SummaryManager` is an optional component that uses an external Large Language Model (LLM) to generate summaries of ongoing conversations.

-   **Purpose:** It helps provide a high-level overview of a session's activity without requiring a user to read the entire transcript.
-   **Trigger Mechanism:** The summarization process is not based on time but on activity. As defined in `internal/transcript/summary.go`, the `SummaryManager` is triggered to generate a new summary only after a configurable number of new messages (`update_interval`) have been processed since the last summary was created.
-   **External LLM Call:** When a summary is due, the `SummaryManager` formats the most recent messages into a prompt and executes a configurable external shell command (e.g., `llm -m gpt-4o-mini`). It passes the prompt to this command and stores the resulting summary text in the session's database record. This design decouples `clogs` from any specific LLM provider.